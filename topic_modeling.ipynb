{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>visual_img</th>\n",
       "      <th>legend_img</th>\n",
       "      <th>text</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Week 01: A week of clocks</td>\n",
       "      <td>Giorgia</td>\n",
       "      <td>01_Giorgia_DearData_01_Front.jpg</td>\n",
       "      <td>01_Giorgia_DearData_01_Back.jpg</td>\n",
       "      <td>[{\"header\": \"The topic:\", \"content\": \" This wa...</td>\n",
       "      <td>This was the first week of Dear Data – I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Week 01: A week of clocks</td>\n",
       "      <td>Stefanie</td>\n",
       "      <td>01_Stefanie_DearData_01+front.jpg</td>\n",
       "      <td>01_Stefanie_DearData_01+back.jpg</td>\n",
       "      <td>[{\"header\": \"Data-gathering:\", \"content\": \" Or...</td>\n",
       "      <td>Originally Giorgia and I thought that we woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Week 02: A week of public transportation</td>\n",
       "      <td>Giorgia</td>\n",
       "      <td>02_Giorgia_DearData_02_Front.jpg</td>\n",
       "      <td>02_Giorgia_DearData_02_Back.jpg</td>\n",
       "      <td>[{\"header\": \"Data gathering:\", \"content\": \" Th...</td>\n",
       "      <td>This week I collected data on my walks and tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Week 02: A week of public transportation</td>\n",
       "      <td>Stefanie</td>\n",
       "      <td>02_Stefanie_DearData_02+front.jpg</td>\n",
       "      <td>02_Stefanie_DearData_02+back.jpg</td>\n",
       "      <td>[{\"header\": \"Data-gathering:\", \"content\": \" La...</td>\n",
       "      <td>Last week’s intensive data gathering means th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Week 03: A week of thank yous</td>\n",
       "      <td>Giorgia</td>\n",
       "      <td>03_Giorgia_DearData_03_Front.jpg</td>\n",
       "      <td>03_Giorgia_DearData_03_Back.jpg</td>\n",
       "      <td>[{\"header\": \"The topic:\", \"content\": \" This we...</td>\n",
       "      <td>This week we wanted to see how kind we are, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week                                     title    author  \\\n",
       "0     1                 Week 01: A week of clocks   Giorgia   \n",
       "1     1                 Week 01: A week of clocks  Stefanie   \n",
       "2     2  Week 02: A week of public transportation   Giorgia   \n",
       "3     2  Week 02: A week of public transportation  Stefanie   \n",
       "4     3             Week 03: A week of thank yous   Giorgia   \n",
       "\n",
       "                          visual_img                        legend_img  \\\n",
       "0   01_Giorgia_DearData_01_Front.jpg   01_Giorgia_DearData_01_Back.jpg   \n",
       "1  01_Stefanie_DearData_01+front.jpg  01_Stefanie_DearData_01+back.jpg   \n",
       "2   02_Giorgia_DearData_02_Front.jpg   02_Giorgia_DearData_02_Back.jpg   \n",
       "3  02_Stefanie_DearData_02+front.jpg  02_Stefanie_DearData_02+back.jpg   \n",
       "4   03_Giorgia_DearData_03_Front.jpg   03_Giorgia_DearData_03_Back.jpg   \n",
       "\n",
       "                                                text  \\\n",
       "0  [{\"header\": \"The topic:\", \"content\": \" This wa...   \n",
       "1  [{\"header\": \"Data-gathering:\", \"content\": \" Or...   \n",
       "2  [{\"header\": \"Data gathering:\", \"content\": \" Th...   \n",
       "3  [{\"header\": \"Data-gathering:\", \"content\": \" La...   \n",
       "4  [{\"header\": \"The topic:\", \"content\": \" This we...   \n",
       "\n",
       "                                                 doc  \n",
       "0   This was the first week of Dear Data – I was ...  \n",
       "1   Originally Giorgia and I thought that we woul...  \n",
       "2   This week I collected data on my walks and tr...  \n",
       "3   Last week’s intensive data gathering means th...  \n",
       "4   This week we wanted to see how kind we are, a...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "df = pd.read_csv('deardata.csv')\n",
    "def parse_text(row):\n",
    "    t = json.loads(row[5])\n",
    "    s = ''\n",
    "    for item in t:\n",
    "        s+=item['content']\n",
    "    return s\n",
    "\n",
    "df['doc'] = df.apply(parse_text, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(list(df['doc']))\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(list(df['doc']))\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "no_topics = 10\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF-----------------------------\n",
      "Topic 0:\n",
      "time stefanie dear postcard new people kind topic boyfriend postcards\n",
      "Topic 1:\n",
      "giorgia card gathering drawing like ve husband think just quite\n",
      "Topic 2:\n",
      "sounds sound birds subway london hear home background reminds hour\n",
      "Topic 3:\n",
      "envy feelings negative positive envious feeling thoughts negativity festival language\n",
      "Topic 4:\n",
      "clothes wardrobe clothing wear dresses cycling worn organise dress changes\n",
      "Topic 5:\n",
      "books bookshelf book read selection apartment survey italy room old\n",
      "Topic 6:\n",
      "swear words swearing word speak use language italian used situation\n",
      "Topic 7:\n",
      "met festival people eyeo minneapolis talk meeting new time drinks\n",
      "Topic 8:\n",
      "music songs listen tracks old listening past years older driven\n",
      "Topic 9:\n",
      "foods food eat dinner suggested chocolate boyfriend love dataset uk\n",
      "LDA-----------------------------\n",
      "Topic 0:\n",
      "makes words thoughts eventually stopped houses end situations second laugh\n",
      "Topic 1:\n",
      "positive drawing time giorgia card little like work life boyfriend\n",
      "Topic 2:\n",
      "card stefanie friends time drawing postcard like distraction new think\n",
      "Topic 3:\n",
      "time like card giorgia postcard drawing people just think ve\n",
      "Topic 4:\n",
      "like drawing card don time books giorgia stefanie new feel\n",
      "Topic 5:\n",
      "smell smells like ve postcard york word surroundings days time\n",
      "Topic 6:\n",
      "swear words drawing time like swearing card giorgia gathering word\n",
      "Topic 7:\n",
      "people smile tracking card different giorgia smiles think ones person\n",
      "Topic 8:\n",
      "london past music city like ve giorgia new brixton card\n",
      "Topic 9:\n",
      "time like giorgia just card drawing people new don really\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 10\n",
    "print('NMF-----------------------------')\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "print('LDA-----------------------------')\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
